{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a51799",
   "metadata": {},
   "source": [
    "# Generating raw dataset using Python Faker Library.üìäüêç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c50e63",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e7af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef82111",
   "metadata": {},
   "source": [
    "Creating a Faker class object.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875a5e8",
   "metadata": {},
   "source": [
    "Define constants like number of rows and noisy rows in your dataset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd443d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 300_000\n",
    "noise_rows = 50_000\n",
    "product_categories = [\"Electronics\", \"Clothing\", \"Books\", \"Toys\", \"Groceries\"]\n",
    "payment_methods = [\"Credit Card\", \"Debit Card\", \"UPI\", \"Cash\", \"Bank Transfer\"]\n",
    "null_chance = 0.03  # 3% chance a field will be None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad846fe3",
   "metadata": {},
   "source": [
    "Dummy method to inject `NULL` values in your dataset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b6b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_null(value, null_probability=null_chance):\n",
    "    return value if random.random() > null_probability else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713d06b",
   "metadata": {},
   "source": [
    "Method to generate dataset with necessary columns and with dummy data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393ae053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_row():\n",
    "    row = {\n",
    "        # Invoice Info\n",
    "        \"invoice_id\": maybe_null(fake.uuid4()),\n",
    "        \"invoice_date\": maybe_null(fake.date_between(start_date='-2y', end_date='today')),\n",
    "\n",
    "        # Product Info\n",
    "        \"product_id\": maybe_null(fake.uuid4()),\n",
    "        \"product_name\": maybe_null(fake.word().capitalize() + \" \" + random.choice(product_categories)),\n",
    "        \"product_category\": maybe_null(random.choice(product_categories)),\n",
    "        \"price\": maybe_null(round(random.uniform(1, 10000), 2)),\n",
    "        \"quantity\": maybe_null(random.randint(1, 200)),\n",
    "\n",
    "        # Payment Info\n",
    "        \"payment_method\": maybe_null(random.choice(payment_methods)),\n",
    "\n",
    "        # Customer Info\n",
    "        \"customer_id\": maybe_null(fake.uuid4()),\n",
    "        \"customer_name\": maybe_null(fake.name()),\n",
    "        \"customer_age\": maybe_null(random.randint(18, 80)), \n",
    "        \"customer_gender\":(random.choice(['Male', 'Female', 'Other'])),\n",
    "        \"customer_email\":(fake.email()),\n",
    "        \"city\": maybe_null(fake.city()),\n",
    "        \"country\": maybe_null(fake.country()),\n",
    "\n",
    "        # Inventory Info\n",
    "        \"inventory_id\": fake.uuid4(),\n",
    "        \"stock_available\": maybe_null(random.randint(0, 100)),\n",
    "        \"restock_date\": maybe_null(fake.date_between(start_date='today', end_date='+60d')),\n",
    "\n",
    "        # Supplier Info\n",
    "        \"supplier_id\": fake.uuid4(),\n",
    "        \"supplier_name\": maybe_null(fake.company()),\n",
    "        \"supplier_email\":(fake.company_email()),\n",
    "        \"supplier_phone\": maybe_null(fake.msisdn())\n",
    "    }\n",
    "    \n",
    "    # Generate payment_id based on payment_method\n",
    "    payment_method = row[\"payment_method\"]\n",
    "    if payment_method in [\"Credit Card\", \"Debit Card\"]:\n",
    "        row[\"payment_id\"] =fake.credit_card_number(card_type=None)[:12]\n",
    "    elif payment_method == \"UPI\":\n",
    "        row[\"payment_id\"] =fake.bothify(text='??????').upper()\n",
    "    else:  # Cash/Bank Transfer or null\n",
    "        row[\"payment_id\"] =(\"N/A\")\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Generate the dataset\n",
    "data = [generate_row() for _ in range(num_rows)]\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb055b43",
   "metadata": {},
   "source": [
    "Inject some noises in the rows to pre-process them furthur.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33cb2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_realistic_noise(row):\n",
    "    col = random.choice(df.columns)\n",
    "    noise_type = random.choice([\"null\", \"wrong\"])\n",
    "\n",
    "    if noise_type == \"null\":\n",
    "        row[col] = None\n",
    "\n",
    "    elif noise_type == \"wrong\":\n",
    "        if col == \"price\":\n",
    "            row[col] = -abs(row[col])  # negative price\n",
    "        elif col == \"quantity\":\n",
    "            row[col] = -random.randint(1, 10)  # negative quantity\n",
    "        elif col == \"product_category\":\n",
    "            row[col] = \"UnknownCategory\"  # invalid category\n",
    "        elif col == \"customer_name\":\n",
    "            row[col] = ''.join(fake.random_letters(length=10))  # garbled name\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a00dec",
   "metadata": {},
   "source": [
    "Inject some duplicate rows as well.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafd9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplication completed!‚ôä\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Sample 10,000 unique rows to duplicate\n",
    "duplicate_rows = df.sample(n=10000, random_state=42)\n",
    "\n",
    "# Step 3: Create random indices to insert them\n",
    "insert_indices = np.random.choice(df.index, size=10000, replace=False)\n",
    "\n",
    "# Step 4: Reset index to allow safe row shuffling\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "duplicate_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 5: Insert duplicate rows at the random positions\n",
    "df_with_dupes = pd.concat([df, duplicate_rows], ignore_index=True)\n",
    "\n",
    "# Step 6: Shuffle to mix original and duplicate rows randomly\n",
    "df_with_dupes = df_with_dupes.sample(frac=1, random_state=99).reset_index(drop=True)\n",
    "\n",
    "# Step 7: Verify\n",
    "print(\"Duplication completed!‚ôä\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c153896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have the DataFrame `df` with 310000 rows\n",
    "chunk_size = 77500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d4b09",
   "metadata": {},
   "source": [
    "Save a chunk of your original dataset in `csv` format.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185f80ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 saved as CSV.üìù\n"
     ]
    }
   ],
   "source": [
    "# Chunk 1 ‚Üí CSV\n",
    "chunk1 = df_with_dupes.iloc[0:chunk_size]\n",
    "chunk1.to_csv(\"chunk_1.csv\", index=False)\n",
    "print(\"Chunk 1 saved as CSV.üìù\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4f616",
   "metadata": {},
   "source": [
    "Save a chunk of your original dataset in `xlsx` format.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9359f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2 saved as Excel.üìà\n"
     ]
    }
   ],
   "source": [
    "# Chunk 2 ‚Üí Excel\n",
    "chunk2 = df_with_dupes.iloc[chunk_size:chunk_size*2]\n",
    "chunk2.to_excel(\"chunk_2.xlsx\", index=False)\n",
    "print(\"Chunk 2 saved as Excel.üìà\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3b59f",
   "metadata": {},
   "source": [
    "Save a chunk of your original dataset in `json` format.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81fdc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 saved as JSON.üè∑Ô∏è\n"
     ]
    }
   ],
   "source": [
    "# Chunk 3 ‚Üí JSON\n",
    "chunk3 = df_with_dupes.iloc[chunk_size*2:chunk_size*3]\n",
    "chunk3.to_json(\"chunk_3.json\", orient=\"records\", lines=True)\n",
    "print(\"Chunk 3 saved as JSON.üè∑Ô∏è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d6fd5",
   "metadata": {},
   "source": [
    "Save a chunk of your original dataset in `DB(sql)` format.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ba78a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4 saved as SQL.üóÉÔ∏è\n"
     ]
    }
   ],
   "source": [
    "# Chunk 4 ‚Üí SQL (SQLite)\n",
    "chunk4 = df_with_dupes.iloc[chunk_size*3:chunk_size*4]\n",
    "conn = sqlite3.connect(\"chunk_4.db\")\n",
    "chunk4.to_sql(\"invoices\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Dump as .sql file\n",
    "with open(\"chunk_4.sql\", \"w\") as f:\n",
    "    for line in conn.iterdump():\n",
    "        f.write(f\"{line}\\n\")\n",
    "conn.close()\n",
    "print(\"Chunk 4 saved as SQL.üóÉÔ∏è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b4b52",
   "metadata": {},
   "source": [
    "# DATA GENERATION COMPLETED. TIME FOR ETL.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
